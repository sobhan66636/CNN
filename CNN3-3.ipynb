{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f9f53cf6",
   "metadata": {},
   "source": [
    "# PHASE 3 - 3 Pretrained Models Transfer Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "270da3a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "TRANSFER LEARNING WITH LOCAL PRETRAINED WEIGHTS\n",
      "======================================================================\n",
      "\n",
      "Loading datasets...\n",
      "Loading cached caltech101 dataset...\n",
      "Train: 6073, Val: 868, Test: 1736\n",
      "Loading cached horse_cat_dog dataset...\n",
      "Train: 424, Val: 60, Test: 122\n",
      "\n",
      "======================================================================\n",
      "PROCESSING Caltech-101\n",
      "======================================================================\n",
      "\n",
      ">>>>> TRAINING MobileNetV2 <<<<<\n",
      "\n",
      "STEP 1: Training classifier head\n",
      "Loading weights from pretrained_weights/mobilenet_v2_weights_tf_dim_ordering_tf_kernels_1.0_224_no_top.h5\n",
      "Training MobileNetV2 on Caltech-101...\n",
      "Epoch 1/15\n",
      "190/190 [==============================] - 66s 321ms/step - loss: 2.9313 - accuracy: 0.4299 - val_loss: 1.4584 - val_accuracy: 0.7224 - lr: 0.0010\n",
      "Epoch 2/15\n",
      "190/190 [==============================] - 59s 312ms/step - loss: 1.6887 - accuracy: 0.6669 - val_loss: 1.0259 - val_accuracy: 0.8214 - lr: 0.0010\n",
      "Epoch 3/15\n",
      "190/190 [==============================] - 59s 309ms/step - loss: 1.2891 - accuracy: 0.7476 - val_loss: 0.9003 - val_accuracy: 0.8364 - lr: 0.0010\n",
      "Epoch 4/15\n",
      "190/190 [==============================] - 60s 315ms/step - loss: 1.0874 - accuracy: 0.7863 - val_loss: 0.8002 - val_accuracy: 0.8652 - lr: 0.0010\n",
      "Epoch 5/15\n",
      "190/190 [==============================] - 58s 307ms/step - loss: 0.9623 - accuracy: 0.8095 - val_loss: 0.7874 - val_accuracy: 0.8537 - lr: 0.0010\n",
      "Epoch 6/15\n",
      "190/190 [==============================] - 58s 307ms/step - loss: 0.8756 - accuracy: 0.8324 - val_loss: 0.7734 - val_accuracy: 0.8433 - lr: 0.0010\n",
      "Epoch 7/15\n",
      "190/190 [==============================] - 58s 304ms/step - loss: 0.8336 - accuracy: 0.8347 - val_loss: 0.8131 - val_accuracy: 0.8514 - lr: 0.0010\n",
      "Epoch 8/15\n",
      "190/190 [==============================] - 57s 301ms/step - loss: 0.7851 - accuracy: 0.8490 - val_loss: 0.7467 - val_accuracy: 0.8594 - lr: 0.0010\n",
      "Epoch 9/15\n",
      "190/190 [==============================] - 58s 305ms/step - loss: 0.7462 - accuracy: 0.8579 - val_loss: 0.7306 - val_accuracy: 0.8675 - lr: 0.0010\n",
      "Epoch 10/15\n",
      "190/190 [==============================] - 58s 305ms/step - loss: 0.7143 - accuracy: 0.8620 - val_loss: 0.7865 - val_accuracy: 0.8514 - lr: 0.0010\n",
      "Epoch 11/15\n",
      "190/190 [==============================] - 59s 310ms/step - loss: 0.7076 - accuracy: 0.8686 - val_loss: 0.7654 - val_accuracy: 0.8548 - lr: 0.0010\n",
      "Epoch 12/15\n",
      "190/190 [==============================] - 58s 304ms/step - loss: 0.6870 - accuracy: 0.8747 - val_loss: 0.7525 - val_accuracy: 0.8687 - lr: 0.0010\n",
      "Epoch 13/15\n",
      "190/190 [==============================] - ETA: 0s - loss: 0.6885 - accuracy: 0.8702\n",
      "Epoch 13: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "190/190 [==============================] - 57s 298ms/step - loss: 0.6885 - accuracy: 0.8702 - val_loss: 0.7579 - val_accuracy: 0.8652 - lr: 0.0010\n",
      "Epoch 14/15\n",
      "190/190 [==============================] - 58s 303ms/step - loss: 0.6166 - accuracy: 0.8912 - val_loss: 0.7089 - val_accuracy: 0.8733 - lr: 5.0000e-04\n",
      "Epoch 15/15\n",
      "190/190 [==============================] - 57s 299ms/step - loss: 0.5865 - accuracy: 0.8907 - val_loss: 0.6801 - val_accuracy: 0.8687 - lr: 5.0000e-04\n",
      "Training completed in 888.6 seconds\n",
      "\n",
      "STEP 2: Fine-tuning top layers\n",
      "Loading weights from pretrained_weights/mobilenet_v2_weights_tf_dim_ordering_tf_kernels_1.0_224_no_top.h5\n",
      "Unfroze 5 top layers\n",
      "Training MobileNetV2 on Caltech-101...\n",
      "Epoch 1/10\n",
      "190/190 [==============================] - 109s 552ms/step - loss: 0.6231 - accuracy: 0.8900 - val_loss: 0.9857 - val_accuracy: 0.8445 - lr: 1.0000e-04\n",
      "Epoch 2/10\n",
      "190/190 [==============================] - 104s 548ms/step - loss: 0.5485 - accuracy: 0.9106 - val_loss: 0.9206 - val_accuracy: 0.8698 - lr: 1.0000e-04\n",
      "Epoch 3/10\n",
      "190/190 [==============================] - 103s 540ms/step - loss: 0.4884 - accuracy: 0.9256 - val_loss: 0.9033 - val_accuracy: 0.8629 - lr: 1.0000e-04\n",
      "Epoch 4/10\n",
      "190/190 [==============================] - 104s 546ms/step - loss: 0.4564 - accuracy: 0.9361 - val_loss: 0.8604 - val_accuracy: 0.8710 - lr: 1.0000e-04\n",
      "Epoch 5/10\n",
      "190/190 [==============================] - 103s 542ms/step - loss: 0.4439 - accuracy: 0.9386 - val_loss: 0.8652 - val_accuracy: 0.8675 - lr: 1.0000e-04\n",
      "Epoch 6/10\n",
      "190/190 [==============================] - 104s 547ms/step - loss: 0.4080 - accuracy: 0.9473 - val_loss: 0.8104 - val_accuracy: 0.8802 - lr: 1.0000e-04\n",
      "Epoch 7/10\n",
      "190/190 [==============================] - 103s 541ms/step - loss: 0.3792 - accuracy: 0.9564 - val_loss: 0.8081 - val_accuracy: 0.8744 - lr: 1.0000e-04\n",
      "Epoch 8/10\n",
      "190/190 [==============================] - 103s 540ms/step - loss: 0.3566 - accuracy: 0.9643 - val_loss: 0.8030 - val_accuracy: 0.8790 - lr: 1.0000e-04\n",
      "Epoch 9/10\n",
      "190/190 [==============================] - 103s 541ms/step - loss: 0.3595 - accuracy: 0.9620 - val_loss: 0.7675 - val_accuracy: 0.8779 - lr: 1.0000e-04\n",
      "Epoch 10/10\n",
      "190/190 [==============================] - 103s 541ms/step - loss: 0.3380 - accuracy: 0.9656 - val_loss: 0.7475 - val_accuracy: 0.8779 - lr: 1.0000e-04\n",
      "Training completed in 1038.4 seconds\n",
      "\n",
      "EVALUATING MODEL...\n",
      "\n",
      "MobileNetV2 on Caltech-101 Results:\n",
      "Accuracy: 0.8635\n",
      "Precision: 0.8699\n",
      "Recall: 0.8635\n",
      "F1-Score: 0.8577\n",
      "AUC: 0.9969\n",
      "\n",
      ">>>>> TRAINING EfficientNetB0 <<<<<\n",
      "\n",
      "STEP 1: Training classifier head\n",
      "Loading weights from pretrained_weights/efficientnetb0_notop.h5\n",
      "Training EfficientNetB0 on Caltech-101...\n",
      "Epoch 1/15\n",
      "190/190 [==============================] - 88s 433ms/step - loss: 4.9486 - accuracy: 0.0440 - val_loss: 4.6603 - val_accuracy: 0.0922 - lr: 0.0010\n",
      "Epoch 2/15\n",
      "190/190 [==============================] - 79s 416ms/step - loss: 4.5860 - accuracy: 0.0899 - val_loss: 4.4130 - val_accuracy: 0.0922 - lr: 0.0010\n",
      "Epoch 3/15\n",
      "190/190 [==============================] - 80s 420ms/step - loss: 4.4776 - accuracy: 0.0973 - val_loss: 4.5150 - val_accuracy: 0.0956 - lr: 0.0010\n",
      "Epoch 4/15\n",
      "190/190 [==============================] - 79s 415ms/step - loss: 4.4141 - accuracy: 0.0930 - val_loss: 4.3981 - val_accuracy: 0.0922 - lr: 0.0010\n",
      "Epoch 5/15\n",
      "190/190 [==============================] - 79s 416ms/step - loss: 4.3668 - accuracy: 0.1001 - val_loss: 4.4181 - val_accuracy: 0.0622 - lr: 0.0010\n",
      "Epoch 6/15\n",
      "190/190 [==============================] - 79s 416ms/step - loss: 4.3242 - accuracy: 0.1054 - val_loss: 4.9638 - val_accuracy: 0.0922 - lr: 0.0010\n",
      "Epoch 7/15\n",
      "190/190 [==============================] - 79s 417ms/step - loss: 4.3103 - accuracy: 0.1051 - val_loss: 10.5952 - val_accuracy: 0.0035 - lr: 0.0010\n",
      "Epoch 8/15\n",
      "190/190 [==============================] - ETA: 0s - loss: 4.3012 - accuracy: 0.1046\n",
      "Epoch 8: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "190/190 [==============================] - 79s 418ms/step - loss: 4.3012 - accuracy: 0.1046 - val_loss: 4.5955 - val_accuracy: 0.0922 - lr: 0.0010\n",
      "Epoch 9/15\n",
      "190/190 [==============================] - 81s 426ms/step - loss: 4.2650 - accuracy: 0.1133 - val_loss: 4.2134 - val_accuracy: 0.1094 - lr: 5.0000e-04\n",
      "Epoch 10/15\n",
      "190/190 [==============================] - 80s 418ms/step - loss: 4.2506 - accuracy: 0.1093 - val_loss: 4.2784 - val_accuracy: 0.1083 - lr: 5.0000e-04\n",
      "Epoch 11/15\n",
      "190/190 [==============================] - 79s 418ms/step - loss: 4.2338 - accuracy: 0.1176 - val_loss: 4.2582 - val_accuracy: 0.0922 - lr: 5.0000e-04\n",
      "Epoch 12/15\n",
      "190/190 [==============================] - 79s 417ms/step - loss: 4.2298 - accuracy: 0.1133 - val_loss: 4.4905 - val_accuracy: 0.0518 - lr: 5.0000e-04\n",
      "Epoch 13/15\n",
      "190/190 [==============================] - ETA: 0s - loss: 4.2286 - accuracy: 0.1172\n",
      "Epoch 13: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "190/190 [==============================] - 80s 419ms/step - loss: 4.2286 - accuracy: 0.1172 - val_loss: 4.2871 - val_accuracy: 0.0922 - lr: 5.0000e-04\n",
      "Epoch 14/15\n",
      "190/190 [==============================] - 80s 419ms/step - loss: 4.2034 - accuracy: 0.1253 - val_loss: 4.3211 - val_accuracy: 0.0853 - lr: 2.5000e-04\n",
      "Epoch 15/15\n",
      "190/190 [==============================] - 80s 420ms/step - loss: 4.2068 - accuracy: 0.1235 - val_loss: 4.2184 - val_accuracy: 0.0933 - lr: 2.5000e-04\n",
      "Training completed in 1202.7 seconds\n",
      "\n",
      "STEP 2: Fine-tuning top layers\n",
      "Loading weights from pretrained_weights/efficientnetb0_notop.h5\n",
      "Unfroze 5 top layers\n",
      "Training EfficientNetB0 on Caltech-101...\n",
      "Epoch 1/10\n",
      "190/190 [==============================] - 140s 697ms/step - loss: 4.4987 - accuracy: 0.0978 - val_loss: 4.8345 - val_accuracy: 0.0922 - lr: 1.0000e-04\n",
      "Epoch 2/10\n",
      "190/190 [==============================] - 131s 689ms/step - loss: 4.4258 - accuracy: 0.1103 - val_loss: 4.3711 - val_accuracy: 0.0968 - lr: 1.0000e-04\n",
      "Epoch 3/10\n",
      "190/190 [==============================] - 130s 686ms/step - loss: 4.4049 - accuracy: 0.1097 - val_loss: 4.1775 - val_accuracy: 0.1371 - lr: 1.0000e-04\n",
      "Epoch 4/10\n",
      "190/190 [==============================] - 129s 680ms/step - loss: 4.3865 - accuracy: 0.1153 - val_loss: 4.1673 - val_accuracy: 0.1233 - lr: 1.0000e-04\n",
      "Epoch 5/10\n",
      "190/190 [==============================] - 129s 678ms/step - loss: 4.3598 - accuracy: 0.1176 - val_loss: 4.1601 - val_accuracy: 0.1187 - lr: 1.0000e-04\n",
      "Epoch 6/10\n",
      "190/190 [==============================] - 130s 686ms/step - loss: 4.3433 - accuracy: 0.1215 - val_loss: 4.1329 - val_accuracy: 0.1509 - lr: 1.0000e-04\n",
      "Epoch 7/10\n",
      "190/190 [==============================] - 129s 680ms/step - loss: 4.3471 - accuracy: 0.1177 - val_loss: 4.1388 - val_accuracy: 0.1382 - lr: 1.0000e-04\n",
      "Epoch 8/10\n",
      "190/190 [==============================] - 129s 680ms/step - loss: 4.3293 - accuracy: 0.1243 - val_loss: 4.1689 - val_accuracy: 0.1164 - lr: 1.0000e-04\n",
      "Epoch 9/10\n",
      "190/190 [==============================] - 130s 683ms/step - loss: 4.3137 - accuracy: 0.1235 - val_loss: 4.1637 - val_accuracy: 0.1129 - lr: 1.0000e-04\n",
      "Epoch 10/10\n",
      "190/190 [==============================] - ETA: 0s - loss: 4.3060 - accuracy: 0.1296\n",
      "Epoch 10: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-05.\n",
      "190/190 [==============================] - 129s 678ms/step - loss: 4.3060 - accuracy: 0.1296 - val_loss: 4.1922 - val_accuracy: 0.1037 - lr: 1.0000e-04\n",
      "Training completed in 1308.1 seconds\n",
      "\n",
      "EVALUATING MODEL...\n",
      "\n",
      "EfficientNetB0 on Caltech-101 Results:\n",
      "Accuracy: 0.0950\n",
      "Precision: 0.0194\n",
      "Recall: 0.0950\n",
      "F1-Score: 0.0217\n",
      "AUC: 0.5965\n",
      "\n",
      ">>>>> TRAINING ResNet50 <<<<<\n",
      "\n",
      "STEP 1: Training classifier head\n",
      "Loading weights from pretrained_weights/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "Training ResNet50 on Caltech-101...\n",
      "Epoch 1/15\n",
      "190/190 [==============================] - 109s 556ms/step - loss: 3.9373 - accuracy: 0.2216 - val_loss: 4.1815 - val_accuracy: 0.1094 - lr: 0.0010\n",
      "Epoch 2/15\n",
      "190/190 [==============================] - 109s 571ms/step - loss: 3.3206 - accuracy: 0.3086 - val_loss: 3.9049 - val_accuracy: 0.2120 - lr: 0.0010\n",
      "Epoch 3/15\n",
      "190/190 [==============================] - 106s 557ms/step - loss: 3.1058 - accuracy: 0.3407 - val_loss: 3.4495 - val_accuracy: 0.2627 - lr: 0.0010\n",
      "Epoch 4/15\n",
      "190/190 [==============================] - 103s 540ms/step - loss: 3.0072 - accuracy: 0.3522 - val_loss: 3.7243 - val_accuracy: 0.2523 - lr: 0.0010\n",
      "Epoch 5/15\n",
      "190/190 [==============================] - 104s 547ms/step - loss: 2.9166 - accuracy: 0.3642 - val_loss: 3.5838 - val_accuracy: 0.3041 - lr: 0.0010\n",
      "Epoch 6/15\n",
      "190/190 [==============================] - 102s 539ms/step - loss: 2.8454 - accuracy: 0.3730 - val_loss: 3.8730 - val_accuracy: 0.2569 - lr: 0.0010\n",
      "Epoch 7/15\n",
      "190/190 [==============================] - ETA: 0s - loss: 2.8146 - accuracy: 0.3779\n",
      "Epoch 7: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "190/190 [==============================] - 103s 540ms/step - loss: 2.8146 - accuracy: 0.3779 - val_loss: 4.6161 - val_accuracy: 0.1982 - lr: 0.0010\n",
      "Epoch 8/15\n",
      "190/190 [==============================] - 105s 551ms/step - loss: 2.7426 - accuracy: 0.3932 - val_loss: 3.1114 - val_accuracy: 0.3237 - lr: 5.0000e-04\n",
      "Epoch 9/15\n",
      "190/190 [==============================] - 104s 549ms/step - loss: 2.6908 - accuracy: 0.4000 - val_loss: 2.9273 - val_accuracy: 0.3571 - lr: 5.0000e-04\n",
      "Epoch 10/15\n",
      "190/190 [==============================] - 104s 549ms/step - loss: 2.6444 - accuracy: 0.4085 - val_loss: 2.8411 - val_accuracy: 0.3802 - lr: 5.0000e-04\n",
      "Epoch 11/15\n",
      "190/190 [==============================] - 102s 536ms/step - loss: 2.6650 - accuracy: 0.4016 - val_loss: 3.2688 - val_accuracy: 0.2938 - lr: 5.0000e-04\n",
      "Epoch 12/15\n",
      "190/190 [==============================] - 102s 539ms/step - loss: 2.6737 - accuracy: 0.4084 - val_loss: 3.2044 - val_accuracy: 0.3191 - lr: 5.0000e-04\n",
      "Epoch 13/15\n",
      "190/190 [==============================] - 102s 538ms/step - loss: 2.6516 - accuracy: 0.4039 - val_loss: 2.9532 - val_accuracy: 0.3744 - lr: 5.0000e-04\n",
      "Epoch 14/15\n",
      "190/190 [==============================] - ETA: 0s - loss: 2.6354 - accuracy: 0.4090\n",
      "Epoch 14: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "190/190 [==============================] - 102s 537ms/step - loss: 2.6354 - accuracy: 0.4090 - val_loss: 2.9288 - val_accuracy: 0.3652 - lr: 5.0000e-04\n",
      "Epoch 15/15\n",
      "190/190 [==============================] - 104s 549ms/step - loss: 2.6218 - accuracy: 0.4098 - val_loss: 2.7180 - val_accuracy: 0.4136 - lr: 2.5000e-04\n",
      "Training completed in 1563.3 seconds\n",
      "\n",
      "STEP 2: Fine-tuning top layers\n",
      "Loading weights from pretrained_weights/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "Unfroze 5 top layers\n",
      "Training ResNet50 on Caltech-101...\n",
      "Epoch 1/10\n",
      "190/190 [==============================] - 154s 791ms/step - loss: 2.9687 - accuracy: 0.3522 - val_loss: 3.3929 - val_accuracy: 0.3030 - lr: 1.0000e-04\n",
      "Epoch 2/10\n",
      "190/190 [==============================] - 149s 785ms/step - loss: 2.6302 - accuracy: 0.4008 - val_loss: 2.6251 - val_accuracy: 0.4090 - lr: 1.0000e-04\n",
      "Epoch 3/10\n",
      "190/190 [==============================] - 147s 775ms/step - loss: 2.5490 - accuracy: 0.4184 - val_loss: 2.8939 - val_accuracy: 0.3929 - lr: 1.0000e-04\n",
      "Epoch 4/10\n",
      "190/190 [==============================] - 149s 785ms/step - loss: 2.4674 - accuracy: 0.4397 - val_loss: 2.4104 - val_accuracy: 0.4608 - lr: 1.0000e-04\n",
      "Epoch 5/10\n",
      "190/190 [==============================] - 147s 773ms/step - loss: 2.4258 - accuracy: 0.4423 - val_loss: 2.4905 - val_accuracy: 0.4435 - lr: 1.0000e-04\n",
      "Epoch 6/10\n",
      "190/190 [==============================] - 149s 785ms/step - loss: 2.4003 - accuracy: 0.4482 - val_loss: 2.3538 - val_accuracy: 0.4793 - lr: 1.0000e-04\n",
      "Epoch 7/10\n",
      "190/190 [==============================] - 147s 776ms/step - loss: 2.3477 - accuracy: 0.4574 - val_loss: 2.6550 - val_accuracy: 0.4078 - lr: 1.0000e-04\n",
      "Epoch 8/10\n",
      "190/190 [==============================] - 147s 774ms/step - loss: 2.3322 - accuracy: 0.4612 - val_loss: 2.5125 - val_accuracy: 0.4516 - lr: 1.0000e-04\n",
      "Epoch 9/10\n",
      "190/190 [==============================] - 150s 787ms/step - loss: 2.3075 - accuracy: 0.4625 - val_loss: 2.2798 - val_accuracy: 0.4816 - lr: 1.0000e-04\n",
      "Epoch 10/10\n",
      "190/190 [==============================] - 147s 773ms/step - loss: 2.2539 - accuracy: 0.4747 - val_loss: 2.6250 - val_accuracy: 0.4297 - lr: 1.0000e-04\n",
      "Training completed in 1487.7 seconds\n",
      "\n",
      "EVALUATING MODEL...\n",
      "\n",
      "ResNet50 on Caltech-101 Results:\n",
      "Accuracy: 0.3969\n",
      "Precision: 0.3663\n",
      "Recall: 0.3969\n",
      "F1-Score: 0.3260\n",
      "AUC: 0.9007\n",
      "\n",
      "======================================================================\n",
      "PROCESSING Horse-Cat-Dog\n",
      "======================================================================\n",
      "\n",
      ">>>>> TRAINING MobileNetV2 <<<<<\n",
      "\n",
      "STEP 1: Training classifier head\n",
      "Loading weights from pretrained_weights/mobilenet_v2_weights_tf_dim_ordering_tf_kernels_1.0_224_no_top.h5\n",
      "Training MobileNetV2 on Horse-Cat-Dog...\n",
      "Epoch 1/15\n",
      "14/14 [==============================] - 8s 380ms/step - loss: 1.2643 - accuracy: 0.6439 - val_loss: 0.6667 - val_accuracy: 0.8833 - lr: 0.0010\n",
      "Epoch 2/15\n",
      "14/14 [==============================] - 4s 292ms/step - loss: 0.6559 - accuracy: 0.8349 - val_loss: 0.6549 - val_accuracy: 0.8833 - lr: 0.0010\n",
      "Epoch 3/15\n",
      "14/14 [==============================] - 4s 290ms/step - loss: 0.5739 - accuracy: 0.8821 - val_loss: 0.6305 - val_accuracy: 0.8833 - lr: 0.0010\n",
      "Epoch 4/15\n",
      "14/14 [==============================] - 5s 339ms/step - loss: 0.4788 - accuracy: 0.9127 - val_loss: 0.6379 - val_accuracy: 0.9000 - lr: 0.0010\n",
      "Epoch 5/15\n",
      "14/14 [==============================] - 4s 290ms/step - loss: 0.4314 - accuracy: 0.9198 - val_loss: 0.5941 - val_accuracy: 0.8833 - lr: 0.0010\n",
      "Epoch 6/15\n",
      "14/14 [==============================] - 4s 290ms/step - loss: 0.4509 - accuracy: 0.9057 - val_loss: 0.5984 - val_accuracy: 0.8833 - lr: 0.0010\n",
      "Epoch 7/15\n",
      "14/14 [==============================] - 5s 341ms/step - loss: 0.4022 - accuracy: 0.9340 - val_loss: 0.6007 - val_accuracy: 0.9167 - lr: 0.0010\n",
      "Epoch 8/15\n",
      "14/14 [==============================] - 4s 294ms/step - loss: 0.3685 - accuracy: 0.9481 - val_loss: 0.6065 - val_accuracy: 0.9167 - lr: 0.0010\n",
      "Epoch 9/15\n",
      "14/14 [==============================] - 4s 292ms/step - loss: 0.3660 - accuracy: 0.9481 - val_loss: 0.5799 - val_accuracy: 0.9167 - lr: 0.0010\n",
      "Epoch 10/15\n",
      "14/14 [==============================] - 4s 294ms/step - loss: 0.3590 - accuracy: 0.9434 - val_loss: 0.5416 - val_accuracy: 0.9167 - lr: 0.0010\n",
      "Epoch 11/15\n",
      "14/14 [==============================] - 4s 295ms/step - loss: 0.3296 - accuracy: 0.9528 - val_loss: 0.5341 - val_accuracy: 0.9167 - lr: 0.0010\n",
      "Epoch 12/15\n",
      "14/14 [==============================] - 4s 296ms/step - loss: 0.3460 - accuracy: 0.9623 - val_loss: 0.5803 - val_accuracy: 0.8833 - lr: 0.0010\n",
      "Epoch 13/15\n",
      "14/14 [==============================] - 4s 294ms/step - loss: 0.3334 - accuracy: 0.9481 - val_loss: 0.5415 - val_accuracy: 0.9000 - lr: 0.0010\n",
      "Epoch 14/15\n",
      "14/14 [==============================] - 4s 295ms/step - loss: 0.3125 - accuracy: 0.9717 - val_loss: 0.5233 - val_accuracy: 0.9167 - lr: 0.0010\n",
      "Epoch 15/15\n",
      "14/14 [==============================] - ETA: 0s - loss: 0.2999 - accuracy: 0.9741Restoring model weights from the end of the best epoch: 7.\n",
      "14/14 [==============================] - 4s 296ms/step - loss: 0.2999 - accuracy: 0.9741 - val_loss: 0.5488 - val_accuracy: 0.9000 - lr: 0.0010\n",
      "Epoch 15: early stopping\n",
      "Training completed in 67.6 seconds\n",
      "\n",
      "STEP 2: Fine-tuning top layers\n",
      "Loading weights from pretrained_weights/mobilenet_v2_weights_tf_dim_ordering_tf_kernels_1.0_224_no_top.h5\n",
      "Unfroze 5 top layers\n",
      "Training MobileNetV2 on Horse-Cat-Dog...\n",
      "Epoch 1/10\n",
      "14/14 [==============================] - 13s 671ms/step - loss: 0.3521 - accuracy: 0.9505 - val_loss: 0.5682 - val_accuracy: 0.9167 - lr: 1.0000e-04\n",
      "Epoch 2/10\n",
      "14/14 [==============================] - 7s 522ms/step - loss: 0.3503 - accuracy: 0.9481 - val_loss: 0.5871 - val_accuracy: 0.9167 - lr: 1.0000e-04\n",
      "Epoch 3/10\n",
      "14/14 [==============================] - 7s 523ms/step - loss: 0.3601 - accuracy: 0.9623 - val_loss: 0.5948 - val_accuracy: 0.9000 - lr: 1.0000e-04\n",
      "Epoch 4/10\n",
      "14/14 [==============================] - 7s 527ms/step - loss: 0.3248 - accuracy: 0.9670 - val_loss: 0.5607 - val_accuracy: 0.9167 - lr: 1.0000e-04\n",
      "Epoch 5/10\n",
      "14/14 [==============================] - 7s 525ms/step - loss: 0.3160 - accuracy: 0.9646 - val_loss: 0.5334 - val_accuracy: 0.9167 - lr: 1.0000e-04\n",
      "Epoch 6/10\n",
      "14/14 [==============================] - 7s 524ms/step - loss: 0.3015 - accuracy: 0.9741 - val_loss: 0.5629 - val_accuracy: 0.9167 - lr: 1.0000e-04\n",
      "Epoch 7/10\n",
      "14/14 [==============================] - 7s 524ms/step - loss: 0.2996 - accuracy: 0.9717 - val_loss: 0.5681 - val_accuracy: 0.9000 - lr: 1.0000e-04\n",
      "Epoch 8/10\n",
      "14/14 [==============================] - 7s 522ms/step - loss: 0.2798 - accuracy: 0.9811 - val_loss: 0.6202 - val_accuracy: 0.9000 - lr: 1.0000e-04\n",
      "Epoch 9/10\n",
      "14/14 [==============================] - ETA: 0s - loss: 0.2989 - accuracy: 0.9693Restoring model weights from the end of the best epoch: 1.\n",
      "\n",
      "Epoch 9: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-05.\n",
      "14/14 [==============================] - 7s 527ms/step - loss: 0.2989 - accuracy: 0.9693 - val_loss: 0.6170 - val_accuracy: 0.9167 - lr: 1.0000e-04\n",
      "Epoch 9: early stopping\n",
      "Training completed in 72.0 seconds\n",
      "\n",
      "EVALUATING MODEL...\n",
      "\n",
      "MobileNetV2 on Horse-Cat-Dog Results:\n",
      "Accuracy: 0.9508\n",
      "Precision: 0.9519\n",
      "Recall: 0.9508\n",
      "F1-Score: 0.9511\n",
      "AUC: 0.9938\n",
      "\n",
      ">>>>> TRAINING EfficientNetB0 <<<<<\n",
      "\n",
      "STEP 1: Training classifier head\n",
      "Loading weights from pretrained_weights/efficientnetb0_notop.h5\n",
      "Training EfficientNetB0 on Horse-Cat-Dog...\n",
      "Epoch 1/15\n",
      "14/14 [==============================] - 13s 537ms/step - loss: 1.6185 - accuracy: 0.3231 - val_loss: 1.3483 - val_accuracy: 0.3333 - lr: 0.0010\n",
      "Epoch 2/15\n",
      "14/14 [==============================] - 6s 396ms/step - loss: 1.4908 - accuracy: 0.3656 - val_loss: 1.3344 - val_accuracy: 0.3333 - lr: 0.0010\n",
      "Epoch 3/15\n",
      "14/14 [==============================] - 6s 398ms/step - loss: 1.4617 - accuracy: 0.3396 - val_loss: 1.4377 - val_accuracy: 0.3333 - lr: 0.0010\n",
      "Epoch 4/15\n",
      "14/14 [==============================] - 6s 397ms/step - loss: 1.4817 - accuracy: 0.3255 - val_loss: 1.4872 - val_accuracy: 0.3333 - lr: 0.0010\n",
      "Epoch 5/15\n",
      "14/14 [==============================] - 6s 399ms/step - loss: 1.4744 - accuracy: 0.3042 - val_loss: 1.4721 - val_accuracy: 0.3333 - lr: 0.0010\n",
      "Epoch 6/15\n",
      "14/14 [==============================] - 6s 398ms/step - loss: 1.4222 - accuracy: 0.3420 - val_loss: 1.3287 - val_accuracy: 0.3333 - lr: 0.0010\n",
      "Epoch 7/15\n",
      "14/14 [==============================] - 6s 410ms/step - loss: 1.4271 - accuracy: 0.3113 - val_loss: 1.3064 - val_accuracy: 0.3333 - lr: 0.0010\n",
      "Epoch 8/15\n",
      "14/14 [==============================] - 6s 402ms/step - loss: 1.4040 - accuracy: 0.3561 - val_loss: 1.4550 - val_accuracy: 0.3333 - lr: 0.0010\n",
      "Epoch 9/15\n",
      "14/14 [==============================] - ETA: 0s - loss: 1.4064 - accuracy: 0.3160Restoring model weights from the end of the best epoch: 1.\n",
      "14/14 [==============================] - 6s 405ms/step - loss: 1.4064 - accuracy: 0.3160 - val_loss: 1.4672 - val_accuracy: 0.3333 - lr: 0.0010\n",
      "Epoch 9: early stopping\n",
      "Training completed in 58.7 seconds\n",
      "\n",
      "STEP 2: Fine-tuning top layers\n",
      "Loading weights from pretrained_weights/efficientnetb0_notop.h5\n",
      "Unfroze 5 top layers\n",
      "Training EfficientNetB0 on Horse-Cat-Dog...\n",
      "Epoch 1/10\n",
      "14/14 [==============================] - 20s 872ms/step - loss: 1.6386 - accuracy: 0.3349 - val_loss: 1.3471 - val_accuracy: 0.3333 - lr: 1.0000e-04\n",
      "Epoch 2/10\n",
      "14/14 [==============================] - 9s 650ms/step - loss: 1.6608 - accuracy: 0.3396 - val_loss: 1.3478 - val_accuracy: 0.3333 - lr: 1.0000e-04\n",
      "Epoch 3/10\n",
      "14/14 [==============================] - 9s 649ms/step - loss: 1.6613 - accuracy: 0.3113 - val_loss: 1.3386 - val_accuracy: 0.3333 - lr: 1.0000e-04\n",
      "Epoch 4/10\n",
      "14/14 [==============================] - 9s 651ms/step - loss: 1.6953 - accuracy: 0.3373 - val_loss: 1.3343 - val_accuracy: 0.3333 - lr: 1.0000e-04\n",
      "Epoch 5/10\n",
      "14/14 [==============================] - 11s 769ms/step - loss: 1.5946 - accuracy: 0.3844 - val_loss: 1.3343 - val_accuracy: 0.3667 - lr: 1.0000e-04\n",
      "Epoch 6/10\n",
      "14/14 [==============================] - 9s 649ms/step - loss: 1.5748 - accuracy: 0.2712 - val_loss: 1.3328 - val_accuracy: 0.3333 - lr: 1.0000e-04\n",
      "Epoch 7/10\n",
      "14/14 [==============================] - 9s 662ms/step - loss: 1.5764 - accuracy: 0.3373 - val_loss: 1.3277 - val_accuracy: 0.3333 - lr: 1.0000e-04\n",
      "Epoch 8/10\n",
      "14/14 [==============================] - 10s 682ms/step - loss: 1.5928 - accuracy: 0.3420 - val_loss: 1.3235 - val_accuracy: 0.3333 - lr: 1.0000e-04\n",
      "Epoch 9/10\n",
      "14/14 [==============================] - 9s 653ms/step - loss: 1.5414 - accuracy: 0.3113 - val_loss: 1.3242 - val_accuracy: 0.3333 - lr: 1.0000e-04\n",
      "Epoch 10/10\n",
      "14/14 [==============================] - 9s 652ms/step - loss: 1.5121 - accuracy: 0.3514 - val_loss: 1.3270 - val_accuracy: 0.3333 - lr: 1.0000e-04\n",
      "Training completed in 104.9 seconds\n",
      "\n",
      "EVALUATING MODEL...\n",
      "WARNING:tensorflow:5 out of the last 62 calls to <function Model.make_predict_function.<locals>.predict_function at 0x0000023B2361B4C0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "\n",
      "EfficientNetB0 on Horse-Cat-Dog Results:\n",
      "Accuracy: 0.3361\n",
      "Precision: 0.1129\n",
      "Recall: 0.3361\n",
      "F1-Score: 0.1691\n",
      "AUC: 0.5333\n",
      "WARNING:tensorflow:5 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x0000023B2361B4C0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "\n",
      ">>>>> TRAINING ResNet50 <<<<<\n",
      "\n",
      "STEP 1: Training classifier head\n",
      "Loading weights from pretrained_weights/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "Training ResNet50 on Horse-Cat-Dog...\n",
      "Epoch 1/15\n",
      "14/14 [==============================] - 12s 646ms/step - loss: 1.5045 - accuracy: 0.3868 - val_loss: 1.2848 - val_accuracy: 0.3333 - lr: 0.0010\n",
      "Epoch 2/15\n",
      "14/14 [==============================] - 8s 530ms/step - loss: 1.1872 - accuracy: 0.4693 - val_loss: 1.2346 - val_accuracy: 0.3333 - lr: 0.0010\n",
      "Epoch 3/15\n",
      "14/14 [==============================] - 7s 533ms/step - loss: 1.0777 - accuracy: 0.5330 - val_loss: 1.1480 - val_accuracy: 0.3333 - lr: 0.0010\n",
      "Epoch 4/15\n",
      "14/14 [==============================] - 7s 528ms/step - loss: 1.0230 - accuracy: 0.5472 - val_loss: 1.1684 - val_accuracy: 0.3333 - lr: 0.0010\n",
      "Epoch 5/15\n",
      "14/14 [==============================] - 9s 654ms/step - loss: 0.9385 - accuracy: 0.6014 - val_loss: 1.1295 - val_accuracy: 0.3500 - lr: 0.0010\n",
      "Epoch 6/15\n",
      "14/14 [==============================] - 7s 532ms/step - loss: 0.9905 - accuracy: 0.5637 - val_loss: 1.1153 - val_accuracy: 0.3333 - lr: 0.0010\n",
      "Epoch 7/15\n",
      "14/14 [==============================] - 7s 530ms/step - loss: 0.8929 - accuracy: 0.5873 - val_loss: 1.1745 - val_accuracy: 0.3333 - lr: 0.0010\n",
      "Epoch 8/15\n",
      "14/14 [==============================] - 7s 530ms/step - loss: 0.9141 - accuracy: 0.5708 - val_loss: 1.1598 - val_accuracy: 0.3333 - lr: 0.0010\n",
      "Epoch 9/15\n",
      "14/14 [==============================] - 7s 529ms/step - loss: 0.9202 - accuracy: 0.6085 - val_loss: 1.1234 - val_accuracy: 0.3500 - lr: 0.0010\n",
      "Epoch 10/15\n",
      "14/14 [==============================] - ETA: 0s - loss: 0.9197 - accuracy: 0.5943\n",
      "Epoch 10: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "14/14 [==============================] - 9s 656ms/step - loss: 0.9197 - accuracy: 0.5943 - val_loss: 1.1167 - val_accuracy: 0.4000 - lr: 0.0010\n",
      "Epoch 11/15\n",
      "14/14 [==============================] - 7s 531ms/step - loss: 0.9021 - accuracy: 0.5660 - val_loss: 1.1113 - val_accuracy: 0.3667 - lr: 5.0000e-04\n",
      "Epoch 12/15\n",
      "14/14 [==============================] - 9s 663ms/step - loss: 0.8894 - accuracy: 0.5896 - val_loss: 1.0928 - val_accuracy: 0.4667 - lr: 5.0000e-04\n",
      "Epoch 13/15\n",
      "14/14 [==============================] - 9s 687ms/step - loss: 0.8399 - accuracy: 0.6179 - val_loss: 1.0837 - val_accuracy: 0.5333 - lr: 5.0000e-04\n",
      "Epoch 14/15\n",
      "14/14 [==============================] - 7s 532ms/step - loss: 0.8446 - accuracy: 0.6462 - val_loss: 1.0740 - val_accuracy: 0.4167 - lr: 5.0000e-04\n",
      "Epoch 15/15\n",
      "14/14 [==============================] - 7s 531ms/step - loss: 0.8709 - accuracy: 0.6274 - val_loss: 1.0749 - val_accuracy: 0.3667 - lr: 5.0000e-04\n",
      "Training completed in 124.1 seconds\n",
      "\n",
      "STEP 2: Fine-tuning top layers\n",
      "Loading weights from pretrained_weights/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "Unfroze 5 top layers\n",
      "Training ResNet50 on Horse-Cat-Dog...\n",
      "Epoch 1/10\n",
      "14/14 [==============================] - 17s 989ms/step - loss: 1.3167 - accuracy: 0.4693 - val_loss: 1.0821 - val_accuracy: 0.5333 - lr: 1.0000e-04\n",
      "Epoch 2/10\n",
      "14/14 [==============================] - 11s 760ms/step - loss: 0.9580 - accuracy: 0.5943 - val_loss: 1.0843 - val_accuracy: 0.4667 - lr: 1.0000e-04\n",
      "Epoch 3/10\n",
      "14/14 [==============================] - 11s 759ms/step - loss: 0.9424 - accuracy: 0.5849 - val_loss: 1.0932 - val_accuracy: 0.3500 - lr: 1.0000e-04\n",
      "Epoch 4/10\n",
      "14/14 [==============================] - 11s 763ms/step - loss: 0.8468 - accuracy: 0.6250 - val_loss: 1.1084 - val_accuracy: 0.3500 - lr: 1.0000e-04\n",
      "Epoch 5/10\n",
      "14/14 [==============================] - ETA: 0s - loss: 0.8554 - accuracy: 0.6368\n",
      "Epoch 5: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-05.\n",
      "14/14 [==============================] - 11s 759ms/step - loss: 0.8554 - accuracy: 0.6368 - val_loss: 1.1418 - val_accuracy: 0.3333 - lr: 1.0000e-04\n",
      "Epoch 6/10\n",
      "14/14 [==============================] - 11s 758ms/step - loss: 0.8087 - accuracy: 0.6604 - val_loss: 1.1633 - val_accuracy: 0.3333 - lr: 5.0000e-05\n",
      "Epoch 7/10\n",
      "14/14 [==============================] - 11s 760ms/step - loss: 0.6877 - accuracy: 0.7193 - val_loss: 1.1842 - val_accuracy: 0.3333 - lr: 5.0000e-05\n",
      "Epoch 8/10\n",
      "14/14 [==============================] - 11s 760ms/step - loss: 0.7496 - accuracy: 0.7052 - val_loss: 1.2023 - val_accuracy: 0.3333 - lr: 5.0000e-05\n",
      "Epoch 9/10\n",
      "14/14 [==============================] - ETA: 0s - loss: 0.7203 - accuracy: 0.7028Restoring model weights from the end of the best epoch: 1.\n",
      "\n",
      "Epoch 9: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-05.\n",
      "14/14 [==============================] - 11s 772ms/step - loss: 0.7203 - accuracy: 0.7028 - val_loss: 1.2118 - val_accuracy: 0.3333 - lr: 5.0000e-05\n",
      "Epoch 9: early stopping\n",
      "Training completed in 103.2 seconds\n",
      "\n",
      "EVALUATING MODEL...\n",
      "\n",
      "ResNet50 on Horse-Cat-Dog Results:\n",
      "Accuracy: 0.4426\n",
      "Precision: 0.3283\n",
      "Recall: 0.4426\n",
      "F1-Score: 0.3643\n",
      "AUC: 0.7413\n",
      "\n",
      "TRAINING COMPLETED!\n",
      "\n",
      "Total execution time: 137.2 minutes\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tensorflow.keras.applications import ResNet50, MobileNetV2, EfficientNetB0\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Dropout, BatchNormalization\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "from sklearn.metrics import (classification_report, confusion_matrix, \n",
    "                            precision_score, recall_score, f1_score, \n",
    "                            roc_curve, auc, roc_auc_score)\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import label_binarize\n",
    "from tensorflow.keras import regularizers\n",
    "import tensorflow as tf\n",
    "import time\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "# Enable mixed precision for GPU acceleration\n",
    "tf.keras.mixed_precision.set_global_policy('mixed_float16')\n",
    "\n",
    "class OptimizedTransferLearning:\n",
    "    def __init__(self, input_shape=(128, 128, 3)):\n",
    "        self.input_shape = input_shape\n",
    "        self.models_config = {\n",
    "            'ResNet50': ResNet50,\n",
    "            'MobileNetV2': MobileNetV2,\n",
    "            'EfficientNetB0': EfficientNetB0\n",
    "        }\n",
    "        # Local weight paths\n",
    "        self.weight_paths = {\n",
    "            'ResNet50': 'pretrained_weights/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5',\n",
    "            'MobileNetV2': 'pretrained_weights/mobilenet_v2_weights_tf_dim_ordering_tf_kernels_1.0_224_no_top.h5',\n",
    "            'EfficientNetB0': 'pretrained_weights/efficientnetb0_notop.h5'\n",
    "        }\n",
    "        self.model_blocks = {\n",
    "            'ResNet50': ['conv5_block3_out', 'conv4_block6_out', 'conv3_block4_out'],\n",
    "            'MobileNetV2': ['block_16_project_BN', 'block_12_project_BN'],\n",
    "            'EfficientNetB0': ['top_activation', 'block6a_expand_activation']\n",
    "        }\n",
    "        \n",
    "    def load_and_cache_dataset(self, data_dir, dataset_name, target_size=(128, 128)):\n",
    "        \"\"\"Load and cache dataset to avoid reprocessing\"\"\"\n",
    "        cache_path = f\"{dataset_name}_cache.npz\"\n",
    "        \n",
    "        if os.path.exists(cache_path):\n",
    "            print(f\"Loading cached {dataset_name} dataset...\")\n",
    "            cache = np.load(cache_path)\n",
    "            return cache['images'], cache['labels'], cache['class_names']\n",
    "        \n",
    "        print(f\"Processing and caching {dataset_name} dataset...\")\n",
    "        images = []\n",
    "        labels = []\n",
    "        class_names = []\n",
    "        \n",
    "        # Caltech-101 dataset\n",
    "        if dataset_name == 'caltech101':\n",
    "            categories = sorted([d for d in os.listdir(data_dir) \n",
    "                               if os.path.isdir(os.path.join(data_dir, d)) and d != 'BACKGROUND_Google'])[:101]\n",
    "            class_names = categories\n",
    "            \n",
    "            for class_idx, category in enumerate(categories):\n",
    "                category_path = os.path.join(data_dir, category)\n",
    "                image_files = [f for f in os.listdir(category_path) \n",
    "                              if f.lower().endswith(('.jpg', '.jpeg', '.png'))]\n",
    "                \n",
    "                for img_file in image_files:\n",
    "                    try:\n",
    "                        img_path = os.path.join(category_path, img_file)\n",
    "                        img = load_img(img_path, target_size=target_size)\n",
    "                        img_array = img_to_array(img) / 255.0\n",
    "                        images.append(img_array)\n",
    "                        labels.append(class_idx)\n",
    "                    except:\n",
    "                        continue\n",
    "                        \n",
    "        # Horse-Cat-Dog dataset\n",
    "        elif dataset_name == 'horse_cat_dog':\n",
    "            class_names = ['cat', 'dog', 'horse']\n",
    "            for class_idx, class_name in enumerate(class_names):\n",
    "                class_path = os.path.join(data_dir, class_name)\n",
    "                if not os.path.exists(class_path):\n",
    "                    continue\n",
    "                    \n",
    "                image_files = [f for f in os.listdir(class_path) \n",
    "                              if f.lower().endswith(('.jpg', '.jpeg', '.png'))]\n",
    "                \n",
    "                for img_file in image_files:\n",
    "                    try:\n",
    "                        img_path = os.path.join(class_path, img_file)\n",
    "                        img = load_img(img_path, target_size=target_size)\n",
    "                        img_array = img_to_array(img) / 255.0\n",
    "                        images.append(img_array)\n",
    "                        labels.append(class_idx)\n",
    "                    except:\n",
    "                        continue\n",
    "        \n",
    "        images = np.array(images)\n",
    "        labels = np.array(labels)\n",
    "        \n",
    "        print(f\"Caching {len(images)} images...\")\n",
    "        np.savez(cache_path, images=images, labels=labels, class_names=class_names)\n",
    "        \n",
    "        return images, labels, class_names\n",
    "\n",
    "    def split_data(self, X, y, num_classes):\n",
    "        \"\"\"Split data into train/val/test (70/10/20)\"\"\"\n",
    "        # First split: 70% train, 30% temp\n",
    "        X_train, X_temp, y_train, y_temp = train_test_split(\n",
    "            X, y, test_size=0.3, random_state=42, stratify=y\n",
    "        )\n",
    "        \n",
    "        # Second split: 10% val, 20% test (of original)\n",
    "        val_ratio = 0.1 / 0.3\n",
    "        X_val, X_test, y_val, y_test = train_test_split(\n",
    "            X_temp, y_temp, test_size=1 - val_ratio, random_state=42, stratify=y_temp\n",
    "        )\n",
    "        \n",
    "        # Convert to categorical\n",
    "        y_train_cat = to_categorical(y_train, num_classes)\n",
    "        y_val_cat = to_categorical(y_val, num_classes)\n",
    "        y_test_cat = to_categorical(y_test, num_classes)\n",
    "        \n",
    "        print(f\"Train: {X_train.shape[0]}, Val: {X_val.shape[0]}, Test: {X_test.shape[0]}\")\n",
    "        \n",
    "        return X_train, X_val, X_test, y_train_cat, y_val_cat, y_test_cat, y_test\n",
    "\n",
    "    def create_model(self, model_name, num_classes, unfreeze_depth=0):\n",
    "        \"\"\"Create model with selective layer unfreezing and local weights\"\"\"\n",
    "        # Load model without top layers\n",
    "        base_model = self.models_config[model_name](\n",
    "            weights=None,\n",
    "            include_top=False,\n",
    "            input_shape=self.input_shape\n",
    "        )\n",
    "        \n",
    "        # Load local weights\n",
    "        weight_path = self.weight_paths[model_name]\n",
    "        if os.path.exists(weight_path):\n",
    "            print(f\"Loading weights from {weight_path}\")\n",
    "            base_model.load_weights(weight_path)\n",
    "        else:\n",
    "            print(f\"Warning: Weight file not found at {weight_path}\")\n",
    "        \n",
    "        # Freeze all layers initially\n",
    "        base_model.trainable = False\n",
    "        \n",
    "        # Unfreeze top layers if requested\n",
    "        if unfreeze_depth > 0:\n",
    "            # Simplified unfreezing: Unfreeze top 20% of layers\n",
    "            num_layers = len(base_model.layers)\n",
    "            unfreeze_from = int(num_layers-5)  # Unfreeze 5 of layers\n",
    "            \n",
    "            for layer in base_model.layers[unfreeze_from:]:\n",
    "                layer.trainable = True\n",
    "            print(f\"Unfroze {num_layers - unfreeze_from} top layers\")\n",
    "        \n",
    "        # Build model\n",
    "        x = base_model.output\n",
    "        x = GlobalAveragePooling2D()(x)\n",
    "        x = Dense(128, activation='relu', \n",
    "          kernel_regularizer=regularizers.l2(0.001))(x)  # L2 weight regularization\n",
    "        x = BatchNormalization()(x)  # Add batch normalization\n",
    "        x = Dropout(0.5)(x)  # Increase dropout rate\n",
    "        predictions = Dense(num_classes, activation='softmax', dtype='float32')(x)\n",
    "        \n",
    "        model = Model(inputs=base_model.input, outputs=predictions)\n",
    "        return model\n",
    "\n",
    "    def create_data_pipeline(self, X, y, batch_size=64, augment=False):\n",
    "        \"\"\"Create optimized tf.data pipeline\"\"\"\n",
    "        ds = tf.data.Dataset.from_tensor_slices((X, y))\n",
    "        \n",
    "        # Apply augmentation if requested\n",
    "        if augment:\n",
    "            ds = ds.map(\n",
    "                lambda x, y: (tf.image.random_flip_left_right(x), y),\n",
    "                num_parallel_calls=tf.data.AUTOTUNE\n",
    "            )\n",
    "            ds = ds.map(\n",
    "                lambda x, y: (tf.image.random_flip_up_down(x), y),\n",
    "                num_parallel_calls=tf.data.AUTOTUNE\n",
    "            )\n",
    "            ds = ds.map(\n",
    "                lambda x, y: (tf.image.random_brightness(x, 0.15), y),\n",
    "                num_parallel_calls=tf.data.AUTOTUNE\n",
    "            )\n",
    "            ds = ds.map(\n",
    "                lambda x, y: (tf.image.random_saturation(x, 0.8, 1.2), y),\n",
    "                num_parallel_calls=tf.data.AUTOTUNE\n",
    "            )\n",
    "            ds = ds.map(\n",
    "                lambda x, y: (tf.image.random_hue(x, 0.1), y),\n",
    "                num_parallel_calls=tf.data.AUTOTUNE\n",
    "            )\n",
    "            ds = ds.map(\n",
    "                lambda x, y: (tf.image.random_jpeg_quality(x, min_jpeg_quality=75, max_jpeg_quality=95), y),\n",
    "                num_parallel_calls=tf.data.AUTOTUNE\n",
    "            )\n",
    "\n",
    "        ds = ds.batch(batch_size)\n",
    "        ds = ds.prefetch(buffer_size=tf.data.AUTOTUNE)\n",
    "        return ds\n",
    "\n",
    "    def train_model(self, model, train_ds, val_ds, model_name, dataset_name, epochs=20, lr=0.001):\n",
    "        \"\"\"Train model with optimized settings\"\"\"\n",
    "        # Compile model\n",
    "        model.compile(\n",
    "            optimizer=Adam(learning_rate=lr),\n",
    "            loss='categorical_crossentropy',\n",
    "            metrics=['accuracy']\n",
    "        )\n",
    "        \n",
    "        # Callbacks\n",
    "        callbacks = [\n",
    "            EarlyStopping(monitor='val_accuracy', patience=8, restore_best_weights=True, verbose=1),\n",
    "            ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=4, min_lr=1e-6, verbose=1),\n",
    "            ModelCheckpoint(f\"best_{model_name}_{dataset_name}.h5\", \n",
    "                           save_best_only=True, monitor='val_accuracy')\n",
    "        ]\n",
    "        \n",
    "        print(f\"Training {model_name} on {dataset_name}...\")\n",
    "        start_time = time.time()\n",
    "        \n",
    "        history = model.fit(\n",
    "            train_ds,\n",
    "            validation_data=val_ds,\n",
    "            epochs=epochs,\n",
    "            callbacks=callbacks,\n",
    "            verbose=1\n",
    "        )\n",
    "        \n",
    "        train_time = time.time() - start_time\n",
    "        print(f\"Training completed in {train_time:.1f} seconds\")\n",
    "        return history, train_time\n",
    "\n",
    "    def evaluate_model(self, model, test_ds, y_test, class_names):\n",
    "        \"\"\"Comprehensive model evaluation\"\"\"\n",
    "        # Get predictions\n",
    "        y_pred_probs = model.predict(test_ds, verbose=0)\n",
    "        y_pred_labels = np.argmax(y_pred_probs, axis=1)\n",
    "        \n",
    "        # Calculate metrics\n",
    "        test_loss, test_acc = model.evaluate(test_ds, verbose=0)\n",
    "        precision = precision_score(y_test, y_pred_labels, average='weighted')\n",
    "        recall = recall_score(y_test, y_pred_labels, average='weighted')\n",
    "        f1 = f1_score(y_test, y_pred_labels, average='weighted')\n",
    "        \n",
    "        # ROC/AUC\n",
    "        if len(class_names) > 2:\n",
    "            y_test_bin = label_binarize(y_test, classes=np.arange(len(class_names)))\n",
    "            auc_score = roc_auc_score(y_test_bin, y_pred_probs, multi_class='ovr')\n",
    "        else:\n",
    "            auc_score = roc_auc_score(y_test, y_pred_probs[:, 1])\n",
    "        \n",
    "        # Confusion matrix\n",
    "        cm = confusion_matrix(y_test, y_pred_labels)\n",
    "        \n",
    "        return {\n",
    "            'accuracy': test_acc,\n",
    "            'loss': test_loss,\n",
    "            'precision': precision,\n",
    "            'recall': recall,\n",
    "            'f1': f1,\n",
    "            'auc': auc_score,\n",
    "            'cm': cm,\n",
    "            'y_true': y_test,\n",
    "            'y_pred': y_pred_labels,\n",
    "            'y_pred_probs': y_pred_probs\n",
    "        }\n",
    "\n",
    "    def visualize_results(self, results, model_name, dataset_name, class_names):\n",
    "        \"\"\"Generate all required visualizations\"\"\"\n",
    "        # Confusion matrix\n",
    "        plt.figure(figsize=(10, 8))\n",
    "        sns.heatmap(results['cm'], annot=True, fmt='d', cmap='Blues', \n",
    "                   xticklabels=class_names if len(class_names) < 15 else [],\n",
    "                   yticklabels=class_names if len(class_names) < 15 else [])\n",
    "        plt.title(f'{model_name} - {dataset_name} Confusion Matrix')\n",
    "        plt.xlabel('Predicted')\n",
    "        plt.ylabel('True')\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(f'{model_name}_{dataset_name}_confusion.png', dpi=150)\n",
    "        plt.close()\n",
    "        \n",
    "        # ROC Curve (for binary or small multi-class)\n",
    "        if len(class_names) <= 10:\n",
    "            plt.figure(figsize=(8, 6))\n",
    "            \n",
    "            if len(class_names) > 2:\n",
    "                # One-vs-Rest ROC\n",
    "                y_test_bin = label_binarize(results['y_true'], classes=np.arange(len(class_names)))\n",
    "                \n",
    "                for i in range(len(class_names)):\n",
    "                    fpr, tpr, _ = roc_curve(y_test_bin[:, i], results['y_pred_probs'][:, i])\n",
    "                    roc_auc = auc(fpr, tpr)\n",
    "                    plt.plot(fpr, tpr, label=f'{class_names[i]} (AUC = {roc_auc:.2f})')\n",
    "            else:\n",
    "                # Binary ROC\n",
    "                fpr, tpr, _ = roc_curve(results['y_true'], results['y_pred_probs'][:, 1])\n",
    "                roc_auc = auc(fpr, tpr)\n",
    "                plt.plot(fpr, tpr, label=f'ROC curve (AUC = {roc_auc:.2f})')\n",
    "            \n",
    "            plt.plot([0, 1], [0, 1], 'k--')\n",
    "            plt.xlim([0.0, 1.0])\n",
    "            plt.ylim([0.0, 1.05])\n",
    "            plt.xlabel('False Positive Rate')\n",
    "            plt.ylabel('True Positive Rate')\n",
    "            plt.title(f'{model_name} - {dataset_name} ROC Curve')\n",
    "            plt.legend(loc=\"lower right\")\n",
    "            plt.savefig(f'{model_name}_{dataset_name}_roc.png', dpi=150)\n",
    "            plt.close()\n",
    "        \n",
    "        # Metrics comparison\n",
    "        metrics = ['accuracy', 'precision', 'recall', 'f1', 'auc']\n",
    "        values = [results[m] for m in metrics]\n",
    "        \n",
    "        plt.figure(figsize=(10, 6))\n",
    "        bars = plt.bar(metrics, values, color=['blue', 'green', 'red', 'purple', 'orange'])\n",
    "        plt.ylim(0, 1.05)\n",
    "        plt.title(f'{model_name} - {dataset_name} Performance Metrics')\n",
    "        plt.ylabel('Score')\n",
    "        \n",
    "        # Add values on bars\n",
    "        for bar in bars:\n",
    "            height = bar.get_height()\n",
    "            plt.text(bar.get_x() + bar.get_width()/2, height + 0.02,\n",
    "                    f'{height:.3f}', ha='center', va='bottom')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.savefig(f'{model_name}_{dataset_name}_metrics.png', dpi=150)\n",
    "        plt.close()\n",
    "\n",
    "    def visualize_predictions(self, model, X_test, y_test, class_names, num_samples=9):\n",
    "        \"\"\"Visualize test predictions\"\"\"\n",
    "        indices = np.random.choice(len(X_test), num_samples, replace=False)\n",
    "        sample_images = X_test[indices]\n",
    "        sample_labels = y_test[indices]\n",
    "        \n",
    "        preds = model.predict(sample_images, verbose=0)\n",
    "        pred_labels = np.argmax(preds, axis=1)\n",
    "        probs = np.max(preds, axis=1)\n",
    "        \n",
    "        plt.figure(figsize=(12, 8))\n",
    "        for i in range(num_samples):\n",
    "            plt.subplot(3, 3, i+1)\n",
    "            plt.imshow(sample_images[i])\n",
    "            true_label = class_names[sample_labels[i]]\n",
    "            pred_label = class_names[pred_labels[i]]\n",
    "            color = 'green' if sample_labels[i] == pred_labels[i] else 'red'\n",
    "            plt.title(f\"True: {true_label}\\nPred: {pred_label} ({probs[i]:.2f})\", color=color)\n",
    "            plt.axis('off')\n",
    "        plt.tight_layout()\n",
    "        plt.close()\n",
    "\n",
    "def main():\n",
    "    print(\"=\"*70)\n",
    "    print(\"TRANSFER LEARNING WITH LOCAL PRETRAINED WEIGHTS\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    # Initialize with standard ImageNet input size\n",
    "    transfer = OptimizedTransferLearning(input_shape=(128, 128, 3))\n",
    "    \n",
    "    # Create weights directory if not exists\n",
    "    os.makedirs('pretrained_weights', exist_ok=True)\n",
    "    \n",
    "    # Dataset paths - UPDATE THESE\n",
    "    caltech_path = \"caltech-101\"\n",
    "    hcd_path = \"Classification_Horse,Cat,Dog\"\n",
    "    \n",
    "    # Load and cache datasets\n",
    "    print(\"\\nLoading datasets...\")\n",
    "    datasets = []\n",
    "    \n",
    "    if os.path.exists(caltech_path):\n",
    "        try:\n",
    "            X_cal, y_cal, cal_classes = transfer.load_and_cache_dataset(\n",
    "                caltech_path, \"caltech101\", target_size=(128, 128))\n",
    "            X_train_cal, X_val_cal, X_test_cal, y_train_cal, y_val_cal, y_test_cal, y_test_raw_cal = \\\n",
    "                transfer.split_data(X_cal, y_cal, len(cal_classes))\n",
    "            \n",
    "            datasets.append({\n",
    "                'name': 'Caltech-101',\n",
    "                'data': (X_train_cal, X_val_cal, X_test_cal, y_train_cal, y_val_cal, y_test_cal, y_test_raw_cal),\n",
    "                'classes': cal_classes,\n",
    "                'type': 'caltech'\n",
    "            })\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading Caltech-101: {e}\")\n",
    "    \n",
    "    if os.path.exists(hcd_path):\n",
    "        try:\n",
    "            X_hcd, y_hcd, hcd_classes = transfer.load_and_cache_dataset(\n",
    "                hcd_path, \"horse_cat_dog\", target_size=(128, 128))\n",
    "            X_train_hcd, X_val_hcd, X_test_hcd, y_train_hcd, y_val_hcd, y_test_hcd, y_test_raw_hcd = \\\n",
    "                transfer.split_data(X_hcd, y_hcd, len(hcd_classes))\n",
    "            \n",
    "            datasets.append({\n",
    "                'name': 'Horse-Cat-Dog',\n",
    "                'data': (X_train_hcd, X_val_hcd, X_test_hcd, y_train_hcd, y_val_hcd, y_test_hcd, y_test_raw_hcd),\n",
    "                'classes': hcd_classes,\n",
    "                'type': 'hcd'\n",
    "            })\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading Horse-Cat-Dog: {e}\")\n",
    "    \n",
    "    if not datasets:\n",
    "        print(\"No datasets found! Check your paths.\")\n",
    "        return\n",
    "    \n",
    "    # Models to use\n",
    "    models = ['MobileNetV2', 'EfficientNetB0','ResNet50']\n",
    "    \n",
    "    # Training configuration\n",
    "    config = {\n",
    "        'batch_size': 32,\n",
    "        'initial_epochs': 15,\n",
    "        'finetune_epochs': 10,\n",
    "        'initial_lr': 0.001,\n",
    "        'finetune_lr': 0.0001,\n",
    "        'unfreeze_depth': 1\n",
    "    }\n",
    "    \n",
    "    # Process each dataset\n",
    "    for dataset in datasets:\n",
    "        print(f\"\\n{'='*70}\")\n",
    "        print(f\"PROCESSING {dataset['name']}\")\n",
    "        print(f\"{'='*70}\")\n",
    "        \n",
    "        X_train, X_val, X_test, y_train, y_val, y_test, y_test_raw = dataset['data']\n",
    "        class_names = dataset['classes']\n",
    "        num_classes = len(class_names)\n",
    "        \n",
    "        # Create data pipelines\n",
    "        train_ds = transfer.create_data_pipeline(X_train, y_train, \n",
    "                                               batch_size=config['batch_size'], \n",
    "                                               augment=True)\n",
    "        val_ds = transfer.create_data_pipeline(X_val, y_val, \n",
    "                                             batch_size=config['batch_size'])\n",
    "        test_ds = transfer.create_data_pipeline(X_test, y_test, \n",
    "                                              batch_size=config['batch_size'])\n",
    "        \n",
    "        # Process each model\n",
    "        for model_name in models:\n",
    "            print(f\"\\n>>>>> TRAINING {model_name} <<<<<\")\n",
    "            \n",
    "            # Step 1: Train with frozen base\n",
    "            print(\"\\nSTEP 1: Training classifier head\")\n",
    "            try:\n",
    "                model = transfer.create_model(model_name, num_classes, unfreeze_depth=0)\n",
    "                \n",
    "                history_step1, time_step1 = transfer.train_model(\n",
    "                    model, train_ds, val_ds, model_name, dataset['name'],\n",
    "                    epochs=config['initial_epochs'], lr=config['initial_lr']\n",
    "                )\n",
    "            except Exception as e:\n",
    "                print(f\"Error in step 1: {e}\")\n",
    "                continue\n",
    "            \n",
    "            # Step 2: Fine-tune with unfrozen top layers\n",
    "            print(\"\\nSTEP 2: Fine-tuning top layers\")\n",
    "            try:\n",
    "                model = transfer.create_model(model_name, num_classes, \n",
    "                                            unfreeze_depth=config['unfreeze_depth'])\n",
    "                \n",
    "                # Try to load weights from step 1 if available\n",
    "                weight_path = f\"best_{model_name}_{dataset['name']}.h5\"\n",
    "                if os.path.exists(weight_path):\n",
    "                    model.load_weights(weight_path)\n",
    "                \n",
    "                history_step2, time_step2 = transfer.train_model(\n",
    "                    model, train_ds, val_ds, model_name, dataset['name'],\n",
    "                    epochs=config['finetune_epochs'], lr=config['finetune_lr']\n",
    "                )\n",
    "            except Exception as e:\n",
    "                print(f\"Error in step 2: {e}\")\n",
    "                continue\n",
    "            \n",
    "            # Evaluate final model\n",
    "            print(\"\\nEVALUATING MODEL...\")\n",
    "            try:\n",
    "                results = transfer.evaluate_model(model, test_ds, y_test_raw, class_names)\n",
    "                \n",
    "                # Print results\n",
    "                print(f\"\\n{model_name} on {dataset['name']} Results:\")\n",
    "                print(f\"Accuracy: {results['accuracy']:.4f}\")\n",
    "                print(f\"Precision: {results['precision']:.4f}\")\n",
    "                print(f\"Recall: {results['recall']:.4f}\")\n",
    "                print(f\"F1-Score: {results['f1']:.4f}\")\n",
    "                print(f\"AUC: {results['auc']:.4f}\")\n",
    "                \n",
    "                # Generate visualizations\n",
    "                transfer.visualize_results(results, model_name, dataset['name'], class_names)\n",
    "                transfer.visualize_predictions(model, X_test, y_test_raw, class_names)\n",
    "                \n",
    "                # Save classification report\n",
    "                report = classification_report(y_test_raw, results['y_pred'], \n",
    "                                             target_names=class_names, digits=4)\n",
    "                with open(f\"{model_name}_{dataset['name']}_report.txt\", \"w\") as f:\n",
    "                    f.write(report)\n",
    "            except Exception as e:\n",
    "                print(f\"Evaluation error: {e}\")\n",
    "    \n",
    "    print(\"\\nTRAINING COMPLETED!\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Start timer\n",
    "    total_start = time.time()\n",
    "    \n",
    "    # Run main process\n",
    "    main()\n",
    "    \n",
    "    # Calculate total runtime\n",
    "    total_time = time.time() - total_start\n",
    "    print(f\"\\nTotal execution time: {total_time/60:.1f} minutes\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
